{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/requests/__init__.py:89: RequestsDependencyWarning: urllib3 (2.2.1) or chardet (3.0.4) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({}) doesn't match a supported \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../modules')\n",
    "import gzip\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import plotly.express as px\n",
    "\n",
    "#tf.config.set_visible_devices(tf.config.list_physical_devices('GPU')[1], 'GPU')\n",
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print('hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#Open file\n",
    "filepath = '/work/friemer/hgcalml/analysisTidx9'\n",
    "filepath = '/work/friemer/hgcalml/analysisTidx9cocoamatch'\n",
    "filepath = '/work/friemer/hgcalml/analysisFIxedEloss6cocoamatch'\n",
    "filepath = '/work/friemer/hgcalml/analysisJustELossTidxmatch'\n",
    "print('hi')\n",
    "\n",
    "# # Open the file and load the data\n",
    "# with gzip.open(filepath, 'rb') as input_file:\n",
    "#     analysis_data = pickle.load(input_file)\n",
    "    \n",
    "# # Print the keys of the data\n",
    "# print('Analysis data keys:', analysis_data.keys())\n",
    "# print('shower keys ',analysis_data['showers_dataframe'].keys())\n",
    "# print('scalar keys',analysis_data['scalar_variables'].keys())\n",
    "# #print(analysis_data['alpha_ids'])\n",
    "# #print(analysis_data['matched'])\n",
    "# print('features list keys', analysis_data['features'][0].keys())\n",
    "# print('truth list keys', analysis_data['truth'][0].keys())\n",
    "# print('prediction list keys', analysis_data['prediction'][0].keys())\n",
    "\n",
    "# df = analysis_data['showers_dataframe']\n",
    "# feature_list =  analysis_data['features']\n",
    "# t_list = analysis_data['truth']\n",
    "# pred_list = analysis_data['prediction']\n",
    "\n",
    "# df['pred_id_value'] = df['pred_id'].apply(lambda x: np.argmax(x))\n",
    "\n",
    "# has_truth = np.isnan(df['truthHitAssignedEnergies']) == False\n",
    "# has_pred = np.isnan(df['pred_energy']) == False\n",
    "# matched = np.logical_and(has_truth, has_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neutral Efficiency, Fakerate, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 120\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fig\n\u001b[1;32m    119\u001b[0m energy_bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m,\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m10\u001b[39m,\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m30\u001b[39m,\u001b[38;5;241m50\u001b[39m])\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[0;32m--> 120\u001b[0m fig\u001b[38;5;241m=\u001b[39mefficiency_plots(\u001b[43mdf\u001b[49m, bins\u001b[38;5;241m=\u001b[39menergy_bins)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "def help_calc_efficiencies(df, bins, mask=None):\n",
    "    efficiencies = []\n",
    "    efficiencies_err = []\n",
    "    fake_rate = []\n",
    "    fake_rate_err = []\n",
    "    corr_class_prob = []\n",
    "    corr_class_prob_err = []    \n",
    "    \n",
    "    mask_predicted = np.isnan(df['pred_energy']) == False\n",
    "    mask_truth = np.isnan(df['truthHitAssignedEnergies']) == False\n",
    "    \n",
    "    if mask == None:\n",
    "        mask_PID_truth = np.ones(len(df), dtype=bool)\n",
    "        mask_PID_pred = mask_PID_truth\n",
    "    else:\n",
    "        if(mask == 0):\n",
    "            mask_PID_truth = df['truthHitAssignedPIDs'].isin([22])\n",
    "        elif(mask == 1):\n",
    "            mask_PID_truth = df['truthHitAssignedPIDs'].isin([130,310,311,2112,-2112,3122,-3122,3322,-3322])\n",
    "        else:\n",
    "            raise ValueError(\"mask must be 0 or 1\")\n",
    "        print(df[df['pred_id_value']==1]['truthHitAssignedPIDs'])\n",
    "        mask_PID_pred = df['pred_id_value'].isin([mask])\n",
    "        \n",
    "    mask_PID_matched = np.logical_and(mask_PID_truth, mask_PID_pred)\n",
    "        \n",
    "    \n",
    "    for i in range(len(bins) - 1):\n",
    "        mask_bintruth = np.logical_and(\n",
    "            df['truthHitAssignedEnergies'] >= bins[i],\n",
    "            df['truthHitAssignedEnergies'] < bins[i + 1])\n",
    "        mask_binpred = np.logical_and(\n",
    "            df['pred_energy'] >= bins[i],\n",
    "            df['pred_energy'] < bins[i + 1])\n",
    "\n",
    "        matched = np.logical_and(\n",
    "            mask_predicted,\n",
    "            mask_bintruth)\n",
    "        faked = np.logical_and(\n",
    "            mask_binpred,\n",
    "            np.logical_not(mask_truth))\n",
    "        \n",
    "        eff = np.sum(matched[mask_PID_truth]) / np.sum(mask_bintruth[mask_PID_truth])\n",
    "        eff_err = np.sqrt(eff * (1 - eff) / np.sum(matched[mask_PID_truth])) \n",
    "        efficiencies.append(eff)\n",
    "        efficiencies_err.append(eff_err)\n",
    "        \n",
    "        fake = np.sum(faked[mask_PID_pred]) / np.sum(mask_binpred[mask_PID_pred])\n",
    "        fake_err = np.sqrt(fake * (1 - fake) / np.sum(faked[mask_PID_pred]))\n",
    "        fake_rate.append(fake)\n",
    "        fake_rate_err.append(fake_err)\n",
    "        \n",
    "        cc_prob = np.sum(matched[mask_PID_matched]) / np.sum(matched[mask_PID_truth])\n",
    "        cc_prob_err = np.sqrt(cc_prob * (1 - cc_prob) / np.sum(matched[mask_PID_truth]))\n",
    "        corr_class_prob.append(cc_prob)\n",
    "        corr_class_prob_err.append(cc_prob_err)\n",
    "    \n",
    "    return np.array(efficiencies), np.array(efficiencies_err), np.array(fake_rate), np.array(fake_rate_err), np.array(corr_class_prob), np.array(corr_class_prob_err)\n",
    "\n",
    "def efficiency_plots(df, bins):\n",
    "    # Calculate the bin positions and widths\n",
    "    binwidth = bins[1:] - bins[:-1]\n",
    "    x_pos = bins[:-1] + binwidth / 2\n",
    "    x_err = binwidth / 2\n",
    "    \n",
    "    # Calculate the efficiencies and fake rates for the total\n",
    "    yeff, yerr_eff, yfake, yerr_fake, ycorr, yerr_corr = help_calc_efficiencies(df, bins)\n",
    "    yeff, yerr_eff, yfake, yerr_fake, ycorr, yerr_corr = \\\n",
    "        yeff*100, yerr_eff*100, yfake*100, yerr_fake*100, ycorr*100, yerr_corr*100\n",
    "    \n",
    "    # Calculate the efficiencies and fake rates for the photons\n",
    "    yeff_photon, yerr_eff_photon, yfake_photon, yerr_fake_photon, ycorr_photon, yerr_corr_photon = help_calc_efficiencies(df, bins, 0)\n",
    "    yeff_photon, yerr_eff_photon, yfake_photon, yerr_fake_photon, ycorr_photon, yerr_corr_photon = \\\n",
    "        yeff_photon*100, yerr_eff_photon*100, yfake_photon*100, yerr_fake_photon*100, ycorr_photon*100, yerr_corr_photon*100\n",
    "    \n",
    "    # Calculate the efficiencies and fake rates for the neutral hadrons\n",
    "    #130: \"K0L\", 310: \"K0S\", 311: \"K0\", 2112: \"neutron\",-2112: \"antineutron\",3122: \"Lambda\",-3122: \"antilambda\"3322: \"Xi0\",-3322: \"antixi0\"\n",
    "    yeff_nh, yerr_eff_nh, yfake_nh, yerr_fake_nh, ycorr_nh, yerr_corr_nh = help_calc_efficiencies(df, bins, 1)\n",
    "    yeff_nh, yerr_eff_nh, yfake_nh, yerr_fake_nh, ycorr_nh, yerr_corr_nh = \\\n",
    "        yeff_nh*100, yerr_eff_nh*100, yfake_nh*100, yerr_fake_nh*100, ycorr_nh*100, yerr_corr_nh*100\n",
    "    \n",
    "    # Create the plots\n",
    "    fig, ((ax1, ax2, ax3), (ax4, ax5,ax6), (ax7,ax8,ax9)) = plt.subplots(nrows=3, ncols=3, figsize=(20, 10))\n",
    "    ax1.errorbar(x_pos, yeff, xerr=x_err, yerr=yerr_eff, fmt='o', color='red', label='Efficiency')\n",
    "    ax1.set_ylabel('efficiency total', fontsize=10)\n",
    "    ax2.errorbar(x_pos, yeff_photon, xerr=x_err, yerr=yerr_eff_photon, fmt='o', color='red', label='Efficiency')\n",
    "    ax2.set_ylabel('efficiency gamma', fontsize=10)\n",
    "    ax3.errorbar(x_pos, yeff_nh, xerr=x_err, yerr=yerr_eff_nh, fmt='o', color='red', label='Efficiency')\n",
    "    ax3.set_ylabel('efficiency n.H.', fontsize=10)\n",
    "    \n",
    "    ax4.errorbar(x_pos, yfake, xerr=x_err, yerr=yerr_fake, fmt='o', color='red', label='Fake rate')\n",
    "    ax4.set_ylabel('fake rate total', fontsize=10)\n",
    "    ax5.errorbar(x_pos, yfake_photon, xerr=x_err, yerr=yerr_fake_photon, fmt='o', color='red', label='Fake rate')\n",
    "    ax5.set_ylabel('fake rate gamma', fontsize=10)\n",
    "    ax6.errorbar(x_pos, yfake_nh, xerr=x_err, yerr=yerr_fake_nh, fmt='o', color='red', label='Fake rate')\n",
    "    ax6.set_ylabel('fake rate n.H.', fontsize=10)\n",
    "    \n",
    "    ax7.errorbar(x_pos, ycorr, xerr=x_err, yerr=yerr_corr, fmt='o', color='red', label='probability of correct class')\n",
    "    ax7.set_ylabel('p corr total', fontsize=10)\n",
    "    ax8.errorbar(x_pos, ycorr_photon, xerr=x_err, yerr=yerr_corr_photon, fmt='o', color='red', label='probability of correct class')\n",
    "    ax8.set_ylabel('p corr gamma', fontsize=10)\n",
    "    ax9.errorbar(x_pos, ycorr_nh, xerr=x_err, yerr=yerr_corr_nh, fmt='o', color='red', label='probability of correct class')\n",
    "    ax9.set_ylabel('p corr n.H.', fontsize=10)\n",
    "\n",
    "    for ax in [ax1, ax2,ax3, ax4, ax5, ax6, ax7, ax8, ax9]:    \n",
    "        ax.set_xticks(bins)\n",
    "        ax.set_xticklabels(bins, fontsize=10)\n",
    "        ax.set_xlim(bins[0], bins[-1])\n",
    "        ax.grid(True, which='major', axis='y', linestyle='--', alpha=0.5)\n",
    "        ax.grid(True, which='major', axis='x', linestyle='--', alpha=0.5)\n",
    "        ax.set_xlabel('Energy [GeV]', fontsize=10)\n",
    "    \n",
    "        yticks1 = np.round(np.arange(40, 101, 20), 1)\n",
    "        ax.set_yticks(yticks1)\n",
    "        ax.set_yticklabels([f\"{y}%\" for y in yticks1], fontsize=10)\n",
    "        #ax.set_ylim(20, 101)\n",
    "\n",
    "    return fig\n",
    "energy_bins = np.array([1,2,3,4,5,10,20,30,50])*1000\n",
    "fig=efficiency_plots(df, bins=energy_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jet nParticles, deltaE, deltaphi, deltaEta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.18' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "#Jet metrics\n",
    "reseta = []\n",
    "resphi = []\n",
    "relresE = []\n",
    "nParicles_pred = []\n",
    "nParicles_truth = []\n",
    "\n",
    "for i in range(len(t_list)):\n",
    "    eventmask = df['event_id'] == i\n",
    "    mask = np.logical_and(eventmask, matched)\n",
    "    jet_E_truth = np.sum(df[mask]['truthHitAssignedEnergies'])\n",
    "    jet_E_pred = np.sum(df[mask]['pred_energy'])\n",
    "    relresE.append((jet_E_truth-jet_E_pred)/jet_E_truth)\n",
    "    \n",
    "    pred_mask = np.logical_and(eventmask, has_pred)\n",
    "    nParicles_pred.append(np.sum(pred_mask))\n",
    "    truth_mask = np.logical_and(eventmask, has_truth)\n",
    "    nParicles_truth.append(len(np.unique(df[truth_mask]['truthHitAssignementIdx'])))\n",
    "    \n",
    "    t_eta = np.mean(df[mask]['truthHitAssignedZ'])\n",
    "    pred_eta = df[mask]['pred_pos'].apply(lambda x: x[2]).mean()\n",
    "    reseta.append(t_eta-pred_eta)\n",
    "    \n",
    "    t_phi = np.mean(np.arctan2(df[mask]['truthHitAssignedY'], df[mask]['truthHitAssignedX']))\n",
    "    pred_phi = df[mask]['pred_pos'].apply(lambda x: np.arctan2(x[1], x[0])).mean()\n",
    "    delta_phi = t_phi-pred_phi\n",
    "    delta_phi = np.where(delta_phi > np.pi, delta_phi-2*np.pi, delta_phi)\n",
    "    delta_phi = np.where(delta_phi < -np.pi, delta_phi+2*np.pi, delta_phi)\n",
    "    resphi.append(delta_phi)\n",
    "\n",
    "bins = np.linspace(1, 18, 9)\n",
    "plt.hist(nParicles_pred, bins=bins, label='pred', histtype='step')\n",
    "plt.hist(nParicles_truth, bins=bins, label='truth', histtype='step')\n",
    "plt.text(0.95, 0.95, 'Quark Jet', horizontalalignment='right', verticalalignment='top', transform=plt.gca().transAxes)\n",
    "plt.ylabel('Number of events')\n",
    "plt.xlabel('Number of particles in event')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(relresE)\n",
    "plt.ylabel('Number of events')\n",
    "plt.xlabel('Relative Jet energy residual')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(reseta)\n",
    "plt.ylabel('Number of events')\n",
    "plt.xlabel('Jet Eta residual')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(resphi)\n",
    "plt.ylabel('Number of events')\n",
    "plt.xlabel('Jet Phi residual')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neutral Particles E, phi, eta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.18' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "mask_neutral = df['truthHitAssignedPIDs'].isin([22,130, 310, 311, 2112, -2112, 3122, -3122, 3322, -3322])\n",
    "mask_neutral_match = np.logical_and(mask_neutral, matched)\n",
    "\n",
    "#neutral particles \n",
    "reseta = []\n",
    "resphi = []\n",
    "relresE = []\n",
    "\n",
    "for i in range(len(t_list)):\n",
    "    mask = np.logical_and(df['event_id'] == i, mask_neutral_match)\n",
    "    truth_e = df[mask]['truthHitAssignedEnergies']\n",
    "    pred_e = df[mask]['pred_energy']\n",
    "    newrelresE = ((truth_e-pred_e)/truth_e).to_numpy()\n",
    "    relresE = np.concatenate((relresE, newrelresE))\n",
    "    \n",
    "    t_eta = df[mask]['truthHitAssignedZ']\n",
    "    pred_eta = df[mask]['pred_pos'].apply(lambda x: x[2])\n",
    "    delta_eta = (t_eta-pred_eta).to_numpy()\n",
    "    reseta = np.concatenate((reseta, delta_eta))\n",
    "    \n",
    "    t_phi = np.arctan2(df[mask]['truthHitAssignedY'], df[mask]['truthHitAssignedX'])\n",
    "    pred_phi = df[mask]['pred_pos'].apply(lambda x: np.arctan2(x[1], x[0]))\n",
    "    delta_phi = (t_phi-pred_phi).to_numpy()\n",
    "    delta_phi = np.where(delta_phi > np.pi, delta_phi-2*np.pi, delta_phi)\n",
    "    delta_phi = np.where(delta_phi < -np.pi, delta_phi+2*np.pi, delta_phi)\n",
    "\n",
    "    resphi = np.concatenate((resphi, delta_phi))\n",
    "\n",
    "plt.hist(relresE, histtype='step', color='#67c4ce', linestyle='--')\n",
    "plt.ylabel('Number of neutral particles')\n",
    "plt.xlabel('Relative energy residual')\n",
    "plt.show()\n",
    "\n",
    "plt.hist(reseta)\n",
    "plt.xlabel('Eta residual')\n",
    "plt.ylabel('Number of neutral particles')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.hist(resphi)\n",
    "plt.xlabel('Phi residual')\n",
    "plt.ylabel('Number of neutral particles')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charged Energy Resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.18' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def energy_resolution(df, bins=None):\n",
    "    has_truth = np.isnan(df['truthHitAssignedEnergies']) == False\n",
    "    has_pred = np.isnan(df['pred_energy']) == False\n",
    "    matched = np.logical_and(has_truth, has_pred)\n",
    "\n",
    "    means = []\n",
    "    std_error = []\n",
    "\n",
    "    for i in range(len(bins) - 1):\n",
    "        mask_truth_bin = np.logical_and(\n",
    "            df['truthHitAssignedEnergies'] >= bins[i],\n",
    "            df['truthHitAssignedEnergies'] < bins[i + 1])\n",
    "        mask_bin = np.logical_and(mask_truth_bin, matched)\n",
    "        ratios = df['pred_energy'][mask_bin] / df['truthHitAssignedEnergies'][mask_bin]\n",
    "        means.append(np.mean(ratios))\n",
    "        std_error.append(np.std(ratios) / np.sqrt(len(ratios)))\n",
    "\n",
    "    # make boxplots of the ratios for each bin\n",
    "    fig, ax1 = plt.subplots(figsize=(12, 6))\n",
    "    \n",
    "    binwidth = bins[1:] - bins[:-1]\n",
    "    x = bins[:-1] + binwidth / 2\n",
    "    xerr = binwidth / 2    \n",
    "    y = means\n",
    "    yerr = std_error\n",
    "    \n",
    "    # plot x, y with error bars\n",
    "    ax1.errorbar(x, y, xerr=xerr, yerr=yerr, fmt='o', color='blue', zorder=2, label='Mean Response')\n",
    "    \n",
    "    # set xticks\n",
    "    xticks = np.round(bins, 0).astype(int)\n",
    "    ax1.set_xticks(xticks)\n",
    "    ax1.set_xticklabels(xticks, fontsize=20)\n",
    "    ymin = np.round(ax1.get_ylim()[0], 1)\n",
    "    ymax = np.round(ax1.get_ylim()[1], 1)\n",
    "    ydelta = max(1 - ymin, ymax - 1)\n",
    "    ax1.set_ylim(1 - ydelta, 1 + ydelta)    \n",
    "    # set yticks to be evenly spaced around 1\n",
    "    yticks = np.round(np.arange(1 - ydelta, 1 + ydelta, 0.02), 2)\n",
    "    yticks = np.round(np.linspace(1 - ydelta, 1 + ydelta, 11), 2)\n",
    "    ax1.set_yticks(yticks)\n",
    "    ax1.set_yticklabels(yticks, fontsize=20)\n",
    "    \n",
    "    ax1.grid(alpha=0.5, linestyle='--')\n",
    "    ax1.set_ylabel('Mean Response Charged', fontsize=40)\n",
    "    ax1.set_xlabel('Energy [GeV]', fontsize=40)\n",
    "    \n",
    "    return fig\n",
    "\n",
    "\n",
    "energy_bins = np.array([15,20,30,50,200])*1000\n",
    "charged_mask = df['truthHitAssignedPIDs'].isin([11,-11,13,-13,211,-211,321,-321,2212,-2212,3112,-3112,3222,-3222,3312,-3312])\n",
    "fig=energy_resolution(df[charged_mask], bins=energy_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.18' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def plot_condensation(event_id, pred_list, t_list, feature_list, location='/work/friemer/hgcalml/condensationplots/condensation'):\n",
    "    coords = pred_list[event_id]['pred_ccoords']\n",
    "\n",
    "    if coords.shape[1] < 3: #add a zero\n",
    "        coords = tf.concat([coords, tf.zeros_like(coords)[:,0:1]], axis=-1)\n",
    "\n",
    "    data={\n",
    "        'X':  coords[:,0],\n",
    "        'Y':  coords[:,1],\n",
    "        'Z':  coords[:,2],\n",
    "        'hyper_idx': t_list[event_id]['truthHitAssignementIdx'][:,0],\n",
    "        'features': pred_list[event_id]['pred_beta'][:,0],\n",
    "        'pdgid': t_list[event_id]['truthHitAssignedPIDs'][:,0],\n",
    "        'recHitID': feature_list[event_id]['recHitID'][:,0],\n",
    "        }\n",
    "    eventdf = pd.DataFrame(data)\n",
    "\n",
    "    hover_data = {'X': True, 'Y': True, 'Z': True, 'hyper_idx': True,'features': True, 'pdgid': True,'recHitID': True}\n",
    "\n",
    "    fig = px.scatter_3d(eventdf, x=\"X\", y=\"Y\", z=\"Z\", \n",
    "                        color=\"hyper_idx\",\n",
    "                        size='features',\n",
    "                        template='plotly_dark',\n",
    "                        hover_data=hover_data,\n",
    "            color_continuous_scale=px.colors.sequential.Rainbow)\n",
    "    fig.update_traces(marker=dict(line=dict(width=0)))\n",
    "\n",
    "    fig.write_html(location+str(event_id)+\".html\")\n",
    "    return fig\n",
    "\n",
    "#plot_condensation(0, pred_list, t_list, feature_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.18' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def plotDistributions(t_list, feature_list):\n",
    "    n_cells = []\n",
    "    n_tracks = []\n",
    "    photons = []\n",
    "    neutral_hadrons = []\n",
    "    charged_hadrons = []\n",
    "    for i in range(len(t_list)):\n",
    "        n_tracks.append(np.sum(np.abs(feature_list[i]['recHitID'])))\n",
    "        n_cells.append(len(t_list[i]['truthHitAssignementIdx'])-n_tracks[-1])\n",
    "        photons.append(np.sum(t_list[i]['truthHitAssignedPIDs']==22))\n",
    "        neutral_hadrons.append(np.sum(t_list[i]['truthHitAssignedPIDs'].isin([130,310,311,2112,-2112,3122,-3122,3322,-3322])))\n",
    "        charged_hadrons.append(np.sum(t_list[i]['truthHitAssignedPIDs'].isin([11,-11,13,-13,211,-211,321,-321,2212,-2212,3112,-3112,3222,-3222,3312,-3312])))\n",
    "    #create boxplots for the distributions\n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    plt.boxplot([n_cells, n_tracks, photons, neutral_hadrons, charged_hadrons])\n",
    "    plt.set_xticklabels(['n_cells', 'n_tracks', 'photons', 'neutral_hadrons', 'charged_hadrons'])\n",
    "    plt.set_ylabel('Number of particles')\n",
    "    plt.set_title('Number of particles per event')\n",
    "\n",
    "plotDistributions(t_list, feature_list)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.9.18' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
